{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-ranking semántico\n",
    "\n",
    "La **búsqueda por palabras clave**, comúnmente utilizada en motores de búsqueda, prioriza la similitud de palabras entre la consulta del usuario y los documentos disponibles, pero suele ignorar la **semántica** de las palabras. Por ejemplo, no distinguiría entre \"banco\" como institución financiera y \"banco\" como asiento, ya que no comprende las diferencias contextuales y semánticas entre palabras. Por el contrario, la búsqueda semántica sí entiende estas diferencias, brindando resultados más precisos y relevantes.\n",
    "\n",
    "Migrar completamente a sistemas de búsqueda semántica puede ser un reto para muchas empresas debido a la profunda integración de los sistemas basados en palabras clave. Una solución es **re-rankear** los resultados de la búsqueda por palabras clave usando un modelo de búsqueda semántica basado en **word embeddings**.\n",
    "\n",
    "**Cohere Rerank** ofrece una solución de re-ranking semántico fácil de integrar en sistemas existentes, necesitando solo unas pocas líneas de código, permitiendo así una transición suave hacia métodos de búsqueda más avanzados y precisos.\n",
    "\n",
    "Para obtener más información sobre `Cohere Rerank` y cómo puede beneficiar a tu sistema de búsqueda, te invito a visitar su [blog](https://txt.cohere.com/rerank/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Al integrar la precisión contextual de la búsqueda semántica con la eficacia de la búsqueda por palabras clave, podemos superar las limitaciones inherentes de cada método, logrando así resultados de búsqueda más relevantes, precisos y ricos en contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "from dotenv import load_dotenv\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.schema import Document\n",
    "\n",
    "from src.langchain_docs_loader import load_langchain_docs_splitted\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_langchain_docs_splitted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de herramienta de búsqueda por palabras clave\n",
    "\n",
    "BM25 es una función de ranking avanzada usada para clasificar documentos en sistemas de recuperación de información, basándose en su relevancia respecto a una consulta de búsqueda. A diferencia de la búsqueda por palabras clave básica, que solo considera la presencia o ausencia de palabras, BM25 calcula un score de relevancia para cada documento, teniendo en cuenta la frecuencia de aparición del término y su rareza en la colección de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordk_retriever = BM25Retriever.from_documents(docs)\n",
    "\n",
    "\n",
    "def keyword_document_search(query: str, k: int) -> list[Document]:\n",
    "    keywordk_retriever.k = k\n",
    "    return keywordk_retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda de documentos relevantes por palabras clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_keyword_documents = keyword_document_search(\n",
    "    query=\"How to integrate LCEL into my Retrieval augmented generation system with a keyword search retriever?\",\n",
    "    k=100,\n",
    ")\n",
    "\n",
    "print(\"Keyword search results:\")\n",
    "for i, document in enumerate(relevant_keyword_documents):\n",
    "    print(f\"{i+1}. {document.metadata['source']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-ranking semántico de los documentos relevantes\n",
    "\n",
    "Una vez que hemos obtenido los documentos más relevantes para nuestra consulta de búsqueda, podemos re-rankearlos usando un modelo de búsqueda semántica basado en **word embeddings**.\n",
    "\n",
    "En este caso, utilizaremos `Cohere Rerank` para obtener los documentos más relevantes para nuestra consulta de búsqueda, re-rankeando los documentos obtenidos por BM25.\n",
    "\n",
    "Para que `Cohere Rerank` funcione, necesitarás una cuenta de `Cohere` y un `API key`. Puedes obtener tu `API key` [aquí](https://dashboard.cohere.com/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
