{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parent retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al fragmentar documentos para su procesamiento y recuperación, a menudo nos enfrentamos a un dilema: \n",
    "\n",
    "Por un lado, se podrían preferir documentos más reducidos, de modo que los `embeddings` puedan reflejar su significado de manera más exacta y específica. Cuando un documento es demasiado extenso, existe el riesgo de que los `embeddings` pierdan su significado y precisión.\n",
    "\n",
    "Por otro lado, es crucial mantener documentos con una longitud considerable para preservar el contexto de cada fragmento, y así garantizar la coherencia e integridad de la información.\n",
    "\n",
    "`ParentDocumentRetriever` aborda eficazmente esta contradicción al dividir y almacenar fragmentos de datos concisos. Durante el proceso de recuperación, este sistema primero accede a los fragmentos más pequeños y posteriormente identifica y busca los identificadores principales de dichos fragmentos, retornando finalmente los documentos de mayor tamaño. \n",
    "\n",
    "Es crucial aclarar que el término \"documento principal\" hace referencia al documento fuente del que se extrajo un fragmento pequeño. Esto puede ser el documento íntegro original o un segmento más amplio del mismo.\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "Por ejemplo, si se está procesando un libro, podríamos querer fragmentar cada capítulo o sección para obtener `embeddings` más precisos sobre los temas tratados en cada uno. En este caso, un capítulo sería un \"documento principal\", y cada fragmento o sección del capítulo representaría un fragmento más pequeño.\n",
    "\n",
    "1. **Proceso de Fragmentación:**\n",
    "   - El libro se divide en capítulos.\n",
    "   - Cada capítulo se fragmenta en secciones más pequeñas.\n",
    "\n",
    "2. **Proceso de Recuperación:**\n",
    "   - `ParentDocumentRetriever` recupera primero las secciones más pequeñas del capítulo.\n",
    "   - Luego, identifica y recupera el capítulo completo (documento principal) basándose en los fragmentos pequeños.\n",
    "\n",
    "Este enfoque permite una búsqueda y recuperación de información más eficiente y precisa, asegurando que cada fragmento recuperado mantenga su contexto original y, al mismo tiempo, brinde un entendimiento profundo y detallado de su contenido.\n",
    "\n",
    "![Parent Retrievers](../diagrams/slide_diagrama_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from src.langchain_docs_loader import LangchainDocsLoader, num_tokens_from_string\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vectorstore = partial(\n",
    "    Chroma,\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LangchainDocsLoader()\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuperación de los documentos completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cantidad de documentos en nuestra `Store` es igual a la cantidad de documentos en nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al buscar documentos directamente en la `VectorStore`, obtendrás fragmentos de documentos que fueron procesados por el `TextSplitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Does the MultiQueryRetriever might be able to overcome some of the limitations of...?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_documents_similarity = vectorstore.similarity_search(\n",
    "    query,\n",
    ")\n",
    "full_documents_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora realizas una búsqueda en el `ParentDocumentRetriever`, obtendrás los documentos completos.\n",
    "Esto se debe a que el `ParentDocumentRetriever` primero busca los fragmentos que hacen `match` con la `query`, después busca los documentos completos sin repeticiones y finalmente devuelve el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_documents_retriever = retriever.get_relevant_documents(\n",
    "    query,\n",
    ")\n",
    "full_documents_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes corroborar que el `ParentDocumentRetriever` está regresando el subconjunto `único` de documentos completos al comparar el número de documentos recuperados por el `VectorStore` y el `ParentDocumentRetriever`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[doc.metadata[\"source\"] for doc in full_documents_similarity], [\n",
    "    doc.metadata[\"source\"] for doc in full_documents_retriever\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuperación de fragmentos largos en lugar de documentos completos\n",
    "\n",
    "Los documentos pueden ser muy grandes para ser recuperados en su totalidad y ser útiles. \n",
    "\n",
    "Por ejemplo, un documento completo podría ser un libro, pero quizá sólo necesito un capítulo para responder a mi pregunta. O quizá sólo necesito un par de párrafos.\n",
    "\n",
    "Si planeas utilizar los documentos recuperados en un proceso de `Retrival Augmented Generation` (RAG), es posible que los documentos gigantes ni siquiera puedan ser procesados por la ventana de contexto del modelo de lenguaje.\n",
    "\n",
    "Para este caso, el `ParentDocumentRetriever` puede ser configurado para romper los documentos en fragmentos pequeños, buscar sobre ellos y luego devolver fragmentos más largos (sin ser el documento completo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Add parent splitter\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN,\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=num_tokens_from_string,\n",
    ")\n",
    "\n",
    "vectorstore = get_vectorstore(collection_name=\"big_fragments\")\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")\n",
    "\n",
    "retriever.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hay más documentos en el `Store` dado que cada documento se ha dividido en fragmentos más pequeños."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(store.yield_keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.similarity_search(\n",
    "    query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\n",
    "    query,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
