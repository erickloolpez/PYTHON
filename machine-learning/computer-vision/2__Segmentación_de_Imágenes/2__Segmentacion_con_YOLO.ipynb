{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso Computer Vision\n",
    "\n",
    "<img src=\"https://yaelmanuel.com/wp-content/uploads/2021/12/platzi-banner-logo-matematicas.png\" width=\"500px\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instalar dependencias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definir el path del vídeo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"../videos/store.mp4\"\n",
    "# video_path = \"./videos/park_detection.avi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arrancar el proceso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Abrir el video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Crear sustractor de fondo\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(\n",
    "    history=500,          # Número de frames usados para construir el fondo.\n",
    "    varThreshold=16,      # Sensibilidad para detectar cambios\n",
    "    detectShadows=True,   # Detección de sombras\n",
    "    )\n",
    "\n",
    "heatmap_refined = None\n",
    "\n",
    "# Cargar el modelo YOLOv11 para segmentación\n",
    "model = YOLO(\"yolo11n-seg\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Inicializar el acumulador del heatmap en el primer frame\n",
    "    if heatmap_refined is None:\n",
    "        heatmap_refined = np.zeros(frame.shape[:2], dtype=np.float32)\n",
    "\n",
    "    # --- Paso 1: Sustracción de Fondo ---\n",
    "    fgmask = bg_subtractor.apply(frame)\n",
    "    # Umbral para obtener una máscara binaria limpia\n",
    "    _, fgmask = cv2.threshold(fgmask, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # --- Paso 2: Segmentación con YOLO ---\n",
    "    # Realizamos la detección con segmentación sobre el frame completo.\n",
    "    results = model(frame, verbose=False)[0]\n",
    "\n",
    "    # Crear una máscara vacía para acumular las segmentaciones de la clase \"persona\"\n",
    "    segmentation_mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    if results.masks is not None:\n",
    "        # Extraer las máscaras y las clases\n",
    "        masks = results.masks.data.cpu().numpy() if hasattr(results.masks.data, 'cpu') else results.masks.data\n",
    "        classes = results.boxes.cls.cpu().numpy() if hasattr(results.boxes.cls, 'cpu') else results.boxes.cls\n",
    "\n",
    "        for mask, cls in zip(masks, classes):\n",
    "            if int(cls) == 0:  # Filtramos detecciones de persona (en COCO, \"person\" es la clase 0)\n",
    "                mask_bin = (mask > 0.5).astype(np.uint8) * 255\n",
    "                # Redimensionar mask_bin a las dimensiones del frame (o segmentation_mask)\n",
    "                mask_bin_resized = cv2.resize(mask_bin, (segmentation_mask.shape[1], segmentation_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "                segmentation_mask = cv2.bitwise_or(segmentation_mask, mask_bin_resized)\n",
    "\n",
    "    # --- Paso 3: Combinación de Máscaras ---\n",
    "    # Se realiza una intersección entre la máscara de movimiento y la máscara de segmentación de personas\n",
    "    refined_mask = cv2.bitwise_and(fgmask, segmentation_mask)\n",
    "\n",
    "    # Acumulamos la máscara refinada en el heatmap\n",
    "    heatmap_refined = cv2.add(heatmap_refined, refined_mask.astype(np.float32))\n",
    "\n",
    "    # Visualización intermedia\n",
    "    cv2.imshow(\"Frame Original\", frame)\n",
    "    cv2.imshow(\"Mascara Movimiento (FG)\", fgmask)\n",
    "    cv2.imshow(\"Mascara Segmentacion (Personas)\", segmentation_mask)\n",
    "    cv2.imshow(\"Mascara Refinada\", refined_mask)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
