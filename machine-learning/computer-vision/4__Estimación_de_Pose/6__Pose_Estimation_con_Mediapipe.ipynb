{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPutkp55rrj0tKK/S/5USJg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Curso Computer Vision\n","\n","<img src=\"https://yaelmanuel.com/wp-content/uploads/2021/12/platzi-banner-logo-matematicas.png\" width=\"500px\">\n","\n","---"],"metadata":{"id":"DFw47Wmz9anZ"}},{"cell_type":"markdown","source":["**Instalar dependencias**"],"metadata":{"id":"dUGWlZJV9brz"}},{"cell_type":"code","source":["!pip install mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Ej8cpwkeA0f","executionInfo":{"status":"ok","timestamp":1741811546979,"user_tz":180,"elapsed":2316,"user":{"displayName":"Carlos Bustillo","userId":"14895763228834044971"}},"outputId":"b5e3e6bd-175f-4f39-9f09-415394416704"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.1.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n","Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n","Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n","Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.6)\n","Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n","Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n","Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.14.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"]}]},{"cell_type":"markdown","source":["**Definir path del video**"],"metadata":{"id":"TK4MbdCt9eje"}},{"cell_type":"code","source":["video_path = \"/content/head-pose-face-detection-male.mp4\""],"metadata":{"id":"CX2naNbcd3XD","executionInfo":{"status":"ok","timestamp":1741811578513,"user_tz":180,"elapsed":6,"user":{"displayName":"Carlos Bustillo","userId":"14895763228834044971"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5HpIzDcdxbb","executionInfo":{"status":"ok","timestamp":1741811647209,"user_tz":180,"elapsed":34437,"user":{"displayName":"Carlos Bustillo","userId":"14895763228834044971"}},"outputId":"2a55460e-4d1b-4cd0-a72f-0b4238f33d09"},"outputs":[{"output_type":"stream","name":"stdout","text":["Video procesado y guardado en: output_pose_estimation.mp4\n"]}],"source":["import cv2\n","import mediapipe as mp\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def add_gaussian_to_heatmap(heatmap, center, sigma, amplitude):\n","    \"\"\"\n","    Agrega un parche gaussiano al heatmap en la posición 'center'.\n","    heatmap: matriz de activación (h x w).\n","    center: (cx, cy) centro del parche.\n","    sigma: desviación estándar de la gaussiana.\n","    amplitude: valor máximo a sumar.\n","    \"\"\"\n","    h, w = heatmap.shape\n","    y, x = np.indices((h, w))\n","    cx, cy = center\n","    gaussian = amplitude * np.exp(-((x - cx)**2 + (y - cy)**2) / (2 * sigma**2))\n","    heatmap += gaussian\n","    return heatmap\n","\n","# Parámetros\n","output_video_path = \"output_pose_estimation.mp4\"  # Archivo de salida\n","decay_factor = 0.98      # Factor de decaimiento para el heatmap (entre 0 y 1)\n","sigma = 15               # Desviación estándar para el parche gaussiano\n","amplitude = 50           # Amplitud del parche gaussiano\n","\n","# Inicialización de Mediapipe Face Mesh\n","mp_face_mesh = mp.solutions.face_mesh\n","face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5,\n","                                  min_tracking_confidence=0.5,\n","                                  )\n","\n","# Abrir video de entrada y preparar VideoWriter\n","cap = cv2.VideoCapture(video_path)\n","ret, frame = cap.read()\n","h, w, _ = frame.shape\n","\n","# Inicializar heatmap de seguimiento de miradas\n","heatmap_gaze = np.zeros((h, w), dtype=np.float32)\n","\n","# Guardar el archivo output con formato mp4\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","writer = cv2.VideoWriter(output_video_path, fourcc, fps, (w, h))\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Aplicar decay para atenuar activaciones antiguas\n","    heatmap_gaze *= decay_factor\n","\n","    # Procesar frame para estimar pose (Face Mesh)\n","    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    resultados = face_mesh.process(frame_rgb)\n","\n","    if resultados.multi_face_landmarks:\n","        for face_landmarks in resultados.multi_face_landmarks:\n","            # Índices típicos para los ojos: 33 (ojo izquierdo) y 263 (ojo derecho)\n","            left_eye = face_landmarks.landmark[33]\n","            right_eye = face_landmarks.landmark[263]\n","            left_eye_coords = (int(left_eye.x * w), int(left_eye.y * h))\n","            right_eye_coords = (int(right_eye.x * w), int(right_eye.y * h))\n","\n","            # Dibujar los ojos en el frame (opcional)\n","            cv2.circle(frame, left_eye_coords, 3, (0, 255, 0), -1)\n","            cv2.circle(frame, right_eye_coords, 3, (0, 255, 0), -1)\n","\n","            # Aproximar el punto medio entre los ojos (proxy para la dirección de mirada)\n","            mid_eye = (int((left_eye_coords[0] + right_eye_coords[0]) / 2),\n","                       int((left_eye_coords[1] + right_eye_coords[1]) / 2))\n","\n","            # Sumar un parche gaussiano al heatmap en la posición del mid_eye\n","            heatmap_gaze = add_gaussian_to_heatmap(heatmap_gaze, mid_eye, sigma, amplitude)\n","\n","    # Generar una visualización del heatmap\n","    heatmap_vis = cv2.normalize(heatmap_gaze, None, 0, 255, cv2.NORM_MINMAX)\n","    heatmap_vis = np.uint8(heatmap_vis)\n","    colored_heatmap = cv2.applyColorMap(heatmap_vis, cv2.COLORMAP_JET)\n","\n","    # Superponer el heatmap al frame original\n","    overlay = cv2.addWeighted(frame, 0.6, colored_heatmap, 0.4, 0)\n","\n","    # Escribir el frame procesado en el video de salida\n","    writer.write(overlay)\n","\n","cap.release()\n","writer.release()\n","face_mesh.close()\n","\n","print(f\"Video procesado y guardado en: {output_video_path}\")"]}]}