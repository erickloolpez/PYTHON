{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1fm4uYP20LHFFkWTsxHRGaaL-p1bVLvG6",
     "timestamp": 1688058575617
    }
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Hola, mundo en LangChain"
   ],
   "metadata": {
    "id": "X11QtSmiMV9e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instalar librerías principales y configuración de API Key de OpenAI"
   ],
   "metadata": {
    "id": "drFyYyIWMavB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip install langchain pypdf openai chromadb tiktoken"
   ],
   "metadata": {
    "id": "LofnVb23dSxe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688165628049,
     "user_tz": 360,
     "elapsed": 5901,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-02-03T20:37:13.649292Z",
     "start_time": "2025-02-03T20:37:05.970350Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = getpass('Enter the secret value: ')\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ],
   "metadata": {
    "id": "dHG9AVJkh3Dz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688165818015,
     "user_tz": 360,
     "elapsed": 8057,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     }
    },
    "outputId": "616af93a-257b-4cba-81d9-2d2797414792",
    "ExecuteTime": {
     "end_time": "2025-02-03T22:04:22.060455Z",
     "start_time": "2025-02-03T22:04:19.036922Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carga de documents"
   ],
   "metadata": {
    "id": "4Z_Xi-GvMf8E"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T20:38:16.137487Z",
     "start_time": "2025-02-03T20:37:47.674290Z"
    }
   },
   "cell_type": "code",
   "source": "pip install -U langchain-community",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\anaconda\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\anaconda\\lib\\site-packages (from langchain-community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\anaconda\\lib\\site-packages (from langchain-community) (3.9.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.16 in c:\\anaconda\\lib\\site-packages (from langchain-community) (0.3.17)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in c:\\anaconda\\lib\\site-packages (from langchain-community) (0.3.33)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\anaconda\\lib\\site-packages (from langchain-community) (0.3.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\anaconda\\lib\\site-packages (from langchain-community) (1.24.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\anaconda\\lib\\site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\anaconda\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\anaconda\\lib\\site-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (0.3.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\anaconda\\lib\\site-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\anaconda\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\anaconda\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\anaconda\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\anaconda\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\anaconda\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\anaconda\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\anaconda\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\anaconda\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\anaconda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\anaconda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading langchain_community-0.3.16-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.5 MB 991.0 kB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.1/2.5 MB 880.9 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.2/2.5 MB 1.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.5 MB 1.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.5/2.5 MB 2.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.6/2.5 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.9/2.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.2/2.5 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.5/2.5 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.0/2.5 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 4.9 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.9/50.9 kB ? eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, marshmallow, httpx-sse, dataclasses-json, pydantic-settings, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.16 marshmallow-3.26.1 pydantic-settings-2.7.1 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W_6B2k3Vcfxt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688165880499,
     "user_tz": 360,
     "elapsed": 57463,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     }
    },
    "outputId": "862c3d28-9656-41cc-ecde-31daec5f7a6e",
    "ExecuteTime": {
     "end_time": "2025-02-03T20:38:54.650062Z",
     "start_time": "2025-02-03T20:38:19.956674Z"
    }
   },
   "source": [
    "import requests\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "urls = [\n",
    "    'https://arxiv.org/pdf/2306.06031v1.pdf',\n",
    "    'https://arxiv.org/pdf/2306.12156v1.pdf',\n",
    "    'https://arxiv.org/pdf/2306.14289v1.pdf',\n",
    "    'https://arxiv.org/pdf/2305.10973v1.pdf',\n",
    "    'https://arxiv.org/pdf/2306.13643v1.pdf'\n",
    "]\n",
    "\n",
    "ml_papers = []\n",
    "\n",
    "for i, url in enumerate(urls):\n",
    "    response = requests.get(url)\n",
    "    filename = f'paper{i+1}.pdf'\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "        print(f'Descargado {filename}')\n",
    "\n",
    "        loader = PyPDFLoader(filename)\n",
    "        data = loader.load()\n",
    "        ml_papers.extend(data)\n",
    "\n",
    "# Utiliza la lista ml_papers para acceder a los elementos de todos los documentos descargados\n",
    "print('Contenido de ml_papers:')\n",
    "print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargado paper1.pdf\n",
      "Descargado paper2.pdf\n",
      "Descargado paper3.pdf\n",
      "Descargado paper4.pdf\n",
      "Descargado paper5.pdf\n",
      "Contenido de ml_papers:\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "type(ml_papers), len(ml_papers), ml_papers[3]"
   ],
   "metadata": {
    "id": "UgT_gejveKq7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688165880500,
     "user_tz": 360,
     "elapsed": 22,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     }
    },
    "outputId": "2d4161bd-1cb0-4bf2-a038-b685912c000c",
    "ExecuteTime": {
     "end_time": "2025-02-03T20:39:27.500123Z",
     "start_time": "2025-02-03T20:39:27.489165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " 57,\n",
       " Document(metadata={'source': 'paper1.pdf', 'page': 3, 'page_label': '4'}, page_content='Figure 1: FinGPT Framework.\\n4.1 Data Sources\\nThe first stage of the FinGPT pipeline involves the collec-\\ntion of extensive financial data from a wide array of online\\nsources. These include, but are not limited to:\\n• Financial news: Websites such as Reuters, CNBC, Yahoo\\nFinance, among others, are rich sources of financial news\\nand market updates. These sites provide valuable informa-\\ntion on market trends, company earnings, macroeconomic\\nindicators, and other financial events.\\n• Social media: Platforms such as Twitter, Facebook, Red-\\ndit, Weibo, and others, offer a wealth of information in\\nterms of public sentiment, trending topics, and immediate\\nreactions to financial news and events.\\n• Filings: Websites of financial regulatory authorities, such\\nas the SEC in the United States, offer access to company\\nfilings. These filings include annual reports, quarterly earn-\\nings, insider trading reports, and other important company-\\nspecific information. Official websites of stock exchanges\\n(NYSE, NASDAQ, Shanghai Stock Exchange, etc.) pro-\\nvide crucial data on stock prices, trading volumes, company\\nlistings, historical data, and other related information.\\n• Trends: Websites like Seeking Alpha, Google Trends, and\\nother finance-focused blogs and forums provide access to\\nanalysts’ opinions, market predictions, the movement of\\nspecific securities or market segments and investment ad-\\nvice.\\n• Academic datasets: Research-based datasets that offer cu-\\nrated and verified information for sophisticated financial\\nanalysis.\\nTo harness the wealth of information from these diverse\\nsources, FinGPT incorporates data acquisition tools capable\\nof scraping structured and unstructured data, including APIs,\\nweb scraping tools, and direct database access where avail-\\nable. Moreover, the system is designed to respect the terms\\nof service of these platforms, ensuring data collection is ethi-\\ncal and legal.\\nData APIs: In the FinGPT framework, APIs are used not\\nonly for initial data collection but also for real-time data up-\\ndates, ensuring the model is trained on the most current data.\\nAdditionally, error handling and rate-limiting strategies are\\nimplemented to respect API usage limits and avoid disrup-\\ntions in the data flow.\\n4.2 Real-Time Data Engineering Pipeline for\\nFinancial NLP\\nFinancial markets operate in real-time and are highly sensi-\\ntive to news and sentiment. Prices of securities can change\\nrapidly in response to new information, and delays in pro-\\ncessing that information can result in missed opportunities or\\nincreased risk. As a result, real-time processing is essential in\\nfinancial NLP.\\nThe primary challenge with a real-time NLP pipeline is\\nmanaging and processing the continuous inflow of data ef-\\nficiently. The first step in the pipeline is to set up a system to'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split de documents"
   ],
   "metadata": {
    "id": "WJYjDA_GMi0Z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    "    )\n",
    "\n",
    "documents = text_splitter.split_documents(ml_papers)"
   ],
   "metadata": {
    "id": "4caTdNe-hk7w",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688165880500,
     "user_tz": 360,
     "elapsed": 20,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-02-03T21:04:13.376985Z",
     "start_time": "2025-02-03T21:04:13.345103Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "len(documents), documents[10]"
   ],
   "metadata": {
    "id": "koi4gwzthsGh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688165880500,
     "user_tz": 360,
     "elapsed": 20,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     }
    },
    "outputId": "6ed35c64-9026-4222-b86a-379809bfb6dc",
    "ExecuteTime": {
     "end_time": "2025-02-03T21:04:15.270085Z",
     "start_time": "2025-02-03T21:04:15.263401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211,\n",
       " Document(metadata={'source': 'paper1.pdf', 'page': 2, 'page_label': '3'}, page_content='highly volatile, changing rapidly in response to news events\\nor market movements.\\nTrends, often observable through websites like Seeking\\nAlpha, Google Trends, and other finance-oriented blogs and\\nforums, offer critical insights into market movements and in-\\nvestment strategies. They feature:\\n• Analyst perspectives: These platforms provide access to\\nmarket predictions and investment advice from seasoned\\nfinancial analysts and experts.\\n• Market sentiment: The discourse on these platforms can\\nreflect the collective sentiment about specific securities,\\nsectors, or the overall market, providing valuable insights\\ninto the prevailing market mood.\\n• Broad coverage: Trends data spans diverse securities and\\nmarket segments, offering comprehensive market coverage.\\nEach of these data sources provides unique insights into\\nthe financial world. By integrating these diverse data types,\\nfinancial language models like FinGPT can facilitate a com-\\nprehensive understanding of financial markets and enable ef-\\nfective financial decision-making.\\n3.2 Challenges in Handling Financial Data\\nWe summarize three major challenges for handling financial\\ndata as follows:\\n• High temporal sensitivity : Financial data are character-\\nized by their time-sensitive nature. Market-moving news or\\nupdates, once released, provide a narrow window of oppor-\\ntunity for investors to maximize their alpha (the measure of\\nan investment’s relative return).\\n• High dynamism : The financial landscape is perpetually'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embeddings e ingesta a base de datos vectorial"
   ],
   "metadata": {
    "id": "VuGSuQV6MmOA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3}\n",
    "    )"
   ],
   "metadata": {
    "id": "iZ-ZFWgRh9aV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688165966034,
     "user_tz": 360,
     "elapsed": 6756,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-02-03T22:04:28.149430Z",
     "start_time": "2025-02-03T22:04:26.169332Z"
    }
   },
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-or-v1*************************************************************a85f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAuthenticationError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 7\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvectorstores\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Chroma\n\u001B[0;32m      5\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m OpenAIEmbeddings(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-embedding-ada-002\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m vectorstore \u001B[38;5;241m=\u001B[39m Chroma\u001B[38;5;241m.\u001B[39mfrom_documents(\n\u001B[0;32m      8\u001B[0m     documents\u001B[38;5;241m=\u001B[39mdocuments,\n\u001B[0;32m      9\u001B[0m     embedding\u001B[38;5;241m=\u001B[39membeddings\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     12\u001B[0m retriever \u001B[38;5;241m=\u001B[39m vectorstore\u001B[38;5;241m.\u001B[39mas_retriever(\n\u001B[0;32m     13\u001B[0m     search_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mk\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m3\u001B[39m}\n\u001B[0;32m     14\u001B[0m     )\n",
      "File \u001B[1;32mC:\\Anaconda\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:887\u001B[0m, in \u001B[0;36mChroma.from_documents\u001B[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001B[0m\n\u001B[0;32m    885\u001B[0m texts \u001B[38;5;241m=\u001B[39m [doc\u001B[38;5;241m.\u001B[39mpage_content \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[0;32m    886\u001B[0m metadatas \u001B[38;5;241m=\u001B[39m [doc\u001B[38;5;241m.\u001B[39mmetadata \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[1;32m--> 887\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mfrom_texts(\n\u001B[0;32m    888\u001B[0m     texts\u001B[38;5;241m=\u001B[39mtexts,\n\u001B[0;32m    889\u001B[0m     embedding\u001B[38;5;241m=\u001B[39membedding,\n\u001B[0;32m    890\u001B[0m     metadatas\u001B[38;5;241m=\u001B[39mmetadatas,\n\u001B[0;32m    891\u001B[0m     ids\u001B[38;5;241m=\u001B[39mids,\n\u001B[0;32m    892\u001B[0m     collection_name\u001B[38;5;241m=\u001B[39mcollection_name,\n\u001B[0;32m    893\u001B[0m     persist_directory\u001B[38;5;241m=\u001B[39mpersist_directory,\n\u001B[0;32m    894\u001B[0m     client_settings\u001B[38;5;241m=\u001B[39mclient_settings,\n\u001B[0;32m    895\u001B[0m     client\u001B[38;5;241m=\u001B[39mclient,\n\u001B[0;32m    896\u001B[0m     collection_metadata\u001B[38;5;241m=\u001B[39mcollection_metadata,\n\u001B[0;32m    897\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    898\u001B[0m )\n",
      "File \u001B[1;32mC:\\Anaconda\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:843\u001B[0m, in \u001B[0;36mChroma.from_texts\u001B[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001B[0m\n\u001B[0;32m    835\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mchromadb\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbatch_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m create_batches\n\u001B[0;32m    837\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m create_batches(\n\u001B[0;32m    838\u001B[0m         api\u001B[38;5;241m=\u001B[39mchroma_collection\u001B[38;5;241m.\u001B[39m_client,  \u001B[38;5;66;03m# type: ignore[has-type]\u001B[39;00m\n\u001B[0;32m    839\u001B[0m         ids\u001B[38;5;241m=\u001B[39mids,\n\u001B[0;32m    840\u001B[0m         metadatas\u001B[38;5;241m=\u001B[39mmetadatas,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    841\u001B[0m         documents\u001B[38;5;241m=\u001B[39mtexts,\n\u001B[0;32m    842\u001B[0m     ):\n\u001B[1;32m--> 843\u001B[0m         chroma_collection\u001B[38;5;241m.\u001B[39madd_texts(\n\u001B[0;32m    844\u001B[0m             texts\u001B[38;5;241m=\u001B[39mbatch[\u001B[38;5;241m3\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m batch[\u001B[38;5;241m3\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m [],\n\u001B[0;32m    845\u001B[0m             metadatas\u001B[38;5;241m=\u001B[39mbatch[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m batch[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    846\u001B[0m             ids\u001B[38;5;241m=\u001B[39mbatch[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    847\u001B[0m         )\n\u001B[0;32m    848\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    849\u001B[0m     chroma_collection\u001B[38;5;241m.\u001B[39madd_texts(texts\u001B[38;5;241m=\u001B[39mtexts, metadatas\u001B[38;5;241m=\u001B[39mmetadatas, ids\u001B[38;5;241m=\u001B[39mids)\n",
      "File \u001B[1;32mC:\\Anaconda\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:277\u001B[0m, in \u001B[0;36mChroma.add_texts\u001B[1;34m(self, texts, metadatas, ids, **kwargs)\u001B[0m\n\u001B[0;32m    275\u001B[0m texts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(texts)\n\u001B[0;32m    276\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_embedding_function \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 277\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_embedding_function\u001B[38;5;241m.\u001B[39membed_documents(texts)\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m metadatas:\n\u001B[0;32m    279\u001B[0m     \u001B[38;5;66;03m# fill metadatas with empty dicts if somebody\u001B[39;00m\n\u001B[0;32m    280\u001B[0m     \u001B[38;5;66;03m# did not specify metadata for all texts\u001B[39;00m\n\u001B[0;32m    281\u001B[0m     length_diff \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(texts) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mlen\u001B[39m(metadatas)\n",
      "File \u001B[1;32mC:\\Anaconda\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:671\u001B[0m, in \u001B[0;36mOpenAIEmbeddings.embed_documents\u001B[1;34m(self, texts, chunk_size)\u001B[0m\n\u001B[0;32m    668\u001B[0m \u001B[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001B[39;00m\n\u001B[0;32m    669\u001B[0m \u001B[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001B[39;00m\n\u001B[0;32m    670\u001B[0m engine \u001B[38;5;241m=\u001B[39m cast(\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeployment)\n\u001B[1;32m--> 671\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_len_safe_embeddings(texts, engine\u001B[38;5;241m=\u001B[39mengine)\n",
      "File \u001B[1;32mC:\\Anaconda\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:497\u001B[0m, in \u001B[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001B[1;34m(self, texts, engine, chunk_size)\u001B[0m\n\u001B[0;32m    495\u001B[0m batched_embeddings: List[List[\u001B[38;5;28mfloat\u001B[39m]] \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    496\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m _iter:\n\u001B[1;32m--> 497\u001B[0m     response \u001B[38;5;241m=\u001B[39m embed_with_retry(\n\u001B[0;32m    498\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    499\u001B[0m         \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m=\u001B[39mtokens[i : i \u001B[38;5;241m+\u001B[39m _chunk_size],\n\u001B[0;32m    500\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_invocation_params,\n\u001B[0;32m    501\u001B[0m     )\n\u001B[0;32m    502\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    503\u001B[0m         response \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mdict()\n",
      "File \u001B[1;32mC:\\Anaconda\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:120\u001B[0m, in \u001B[0;36membed_with_retry\u001B[1;34m(embeddings, **kwargs)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001B[39;00m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_openai_v1():\n\u001B[1;32m--> 120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m embeddings\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    121\u001B[0m retry_decorator \u001B[38;5;241m=\u001B[39m _create_retry_decorator(embeddings)\n\u001B[0;32m    123\u001B[0m \u001B[38;5;129m@retry_decorator\u001B[39m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_embed_with_retry\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n",
      "File \u001B[1;32mC:\\Anaconda\\Lib\\site-packages\\openai\\resources\\embeddings.py:125\u001B[0m, in \u001B[0;36mEmbeddings.create\u001B[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m    119\u001B[0m         embedding\u001B[38;5;241m.\u001B[39membedding \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfrombuffer(  \u001B[38;5;66;03m# type: ignore[no-untyped-call]\u001B[39;00m\n\u001B[0;32m    120\u001B[0m             base64\u001B[38;5;241m.\u001B[39mb64decode(data), dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloat32\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    121\u001B[0m         )\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m    123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\n\u001B[1;32m--> 125\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post(\n\u001B[0;32m    126\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/embeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    127\u001B[0m     body\u001B[38;5;241m=\u001B[39mmaybe_transform(params, embedding_create_params\u001B[38;5;241m.\u001B[39mEmbeddingCreateParams),\n\u001B[0;32m    128\u001B[0m     options\u001B[38;5;241m=\u001B[39mmake_request_options(\n\u001B[0;32m    129\u001B[0m         extra_headers\u001B[38;5;241m=\u001B[39mextra_headers,\n\u001B[0;32m    130\u001B[0m         extra_query\u001B[38;5;241m=\u001B[39mextra_query,\n\u001B[0;32m    131\u001B[0m         extra_body\u001B[38;5;241m=\u001B[39mextra_body,\n\u001B[0;32m    132\u001B[0m         timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[0;32m    133\u001B[0m         post_parser\u001B[38;5;241m=\u001B[39mparser,\n\u001B[0;32m    134\u001B[0m     ),\n\u001B[0;32m    135\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mCreateEmbeddingResponse,\n\u001B[0;32m    136\u001B[0m )\n",
      "File \u001B[1;32mC:\\Anaconda\\Lib\\site-packages\\openai\\_base_client.py:1283\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1270\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1271\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1278\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1279\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1280\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1281\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1282\u001B[0m     )\n\u001B[1;32m-> 1283\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(cast_to, opts, stream\u001B[38;5;241m=\u001B[39mstream, stream_cls\u001B[38;5;241m=\u001B[39mstream_cls))\n",
      "File \u001B[1;32mC:\\Anaconda\\Lib\\site-packages\\openai\\_base_client.py:960\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    957\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    958\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 960\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[0;32m    961\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[0;32m    962\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m    963\u001B[0m     stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[0;32m    964\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[0;32m    965\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[0;32m    966\u001B[0m )\n",
      "File \u001B[1;32mC:\\Anaconda\\Lib\\site-packages\\openai\\_base_client.py:1064\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1061\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m   1063\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1064\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1066\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[0;32m   1067\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[0;32m   1068\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1072\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[0;32m   1073\u001B[0m )\n",
      "\u001B[1;31mAuthenticationError\u001B[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-or-v1*************************************************************a85f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelos de chat y cadenas para consulta de información"
   ],
   "metadata": {
    "id": "sBbAhkFKMrDC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")"
   ],
   "metadata": {
    "id": "fxjg2e6RiTqO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688165966035,
     "user_tz": 360,
     "elapsed": 13,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     }
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"qué es fingpt?\"\n",
    "qa_chain.run(query)"
   ],
   "metadata": {
    "id": "qgDyf-lOimCT",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688165977030,
     "user_tz": 360,
     "elapsed": 6199,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     }
    },
    "outputId": "18f9ce42-2c78-4540-e6d3-ec5f01223cbb"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'FinGPT es un modelo de lenguaje financiero de código abierto desarrollado por la comunidad AI4Finance. Está diseñado para aplicaciones en el campo de las finanzas y utiliza técnicas de procesamiento de lenguaje natural para analizar y comprender datos financieros. FinGPT adopta un enfoque centrado en los datos y utiliza métodos rigurosos de limpieza y preprocesamiento para garantizar la calidad de los datos. También ofrece un marco de trabajo de extremo a extremo con cuatro capas, que abarca desde la obtención de datos hasta la implementación de aplicaciones prácticas en finanzas. El objetivo de FinGPT es estimular la innovación, democratizar los modelos de lenguaje financiero y desbloquear nuevas oportunidades en el campo de las finanzas abiertas.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"qué hace complicado entrenar un modelo como el fingpt?\"\n",
    "qa_chain.run(query)"
   ],
   "metadata": {
    "id": "rfTiF52Bni8D",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688165991258,
     "user_tz": 360,
     "elapsed": 14230,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     }
    },
    "outputId": "8e6cbcf0-998e-4cad-e11e-7c51fcb12f4e"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Entrenar un modelo como FinGPT puede ser complicado por varias razones. En primer lugar, los modelos de lenguaje grandes requieren una gran cantidad de recursos computacionales, como unidades de procesamiento gráfico (GPU) y tiempo de entrenamiento. En el caso de BloombergGPT, se utilizaron aproximadamente 1.3 millones de horas de GPU para el entrenamiento, lo que se traduce en un costo significativo.\\n\\nAdemás, la adquisición de datos financieros de alta calidad y relevantes puede ser un desafío. Obtener datos financieros históricos o especializados de diferentes fuentes, como plataformas web, API, documentos PDF e imágenes, puede ser complejo debido a los diferentes formatos y tipos de datos.\\n\\nOtro desafío es la naturaleza dinámica del dominio financiero. El mundo financiero está en constante cambio, y los modelos de lenguaje deben actualizarse regularmente para mantener su precisión y relevancia. Esto requiere una capacidad de adaptación rápida y eficiente del modelo, lo cual puede ser complicado de lograr.\\n\\nEn resumen, los desafíos para entrenar un modelo como FinGPT incluyen los altos costos computacionales, la adquisición de datos financieros relevantes y de alta calidad, y la necesidad de actualizaciones frecuentes para adaptarse a los cambios en el dominio financiero.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"qué es fast segment?\"\n",
    "qa_chain.run(query)"
   ],
   "metadata": {
    "id": "MmjAbVyUtLCF",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688165996681,
     "user_tz": 360,
     "elapsed": 5426,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     }
    },
    "outputId": "d40b5c05-ebf2-4eea-e11a-721c9ad9e6e7"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Fast Segment es un método alternativo propuesto en el artículo \"Fast Segment Anything\" para acelerar el modelo Segment Anything (SAM) en tareas de visión por computadora. SAM es un modelo que puede segmentar cualquier objeto en una imagen y ha demostrado resultados prometedores en diversas tareas. Sin embargo, SAM tiene altos costos computacionales debido a su arquitectura Transformer en entradas de alta resolución. Fast Segment propone una forma más rápida de lograr resultados comparables al entrenar un método existente de segmentación de instancias utilizando solo una fracción del conjunto de datos utilizado por SAM. Con Fast Segment, se logra una velocidad de ejecución 50 veces más rápida que SAM sin comprometer significativamente el rendimiento.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"cuál es la diferencia entre fast sam y mobile sam?\"\n",
    "qa_chain.run(query)"
   ],
   "metadata": {
    "id": "4qfwxnkAt_Q8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688166004032,
     "user_tz": 360,
     "elapsed": 7353,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     }
    },
    "outputId": "5ffc4795-48de-4010-c763-da8abaf94c0b"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'La diferencia entre FastSAM y MobileSAM se puede resumir en dos aspectos principales: tamaño y velocidad.\\n\\nEn cuanto al tamaño, MobileSAM es significativamente más pequeño que FastSAM. MobileSAM tiene menos de 10 millones de parámetros, mientras que FastSAM tiene 68 millones de parámetros.\\n\\nEn cuanto a la velocidad, MobileSAM es más rápido que FastSAM. En una GPU individual, MobileSAM tarda solo 10 ms en procesar una imagen, mientras que FastSAM tarda 40 ms. Esto significa que MobileSAM es 4 veces más rápido que FastSAM.\\n\\nAdemás de estas diferencias, también se menciona que MobileSAM tiene un rendimiento superior en términos de mIoU (Índice de Jaccard medio) en comparación con FastSAM. Esto sugiere que la predicción de máscaras de MobileSAM es más similar a la del SAM original que la de FastSAM.\\n\\nEn resumen, MobileSAM es más pequeño, más rápido y tiene un rendimiento superior en comparación con FastSAM.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  }
 ]
}
